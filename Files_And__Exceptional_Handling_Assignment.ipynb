{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1)\n",
        "\n",
        "Solution:\n",
        "\n",
        "Multithreading and multiprocessing are two approaches to achieving in computing, and each has its advantages and ideal scenarios for use.\n",
        "\n",
        "Multithreading:\n",
        "\n",
        "Definition: Multithreading involves running multiple threads (smaller units of a process) within a single process. Threads share the same memory space, making communication between them more efficient.\n",
        "\n",
        "Preferable scenarios:\n",
        "\n",
        "1) I/O-Bound Tasks:\n",
        "\n",
        "When the program spends a lot of time waiting for input/output operations (e.g., reading from disk, network communication), multithreading can keep the CPU busy by switching to other threads while waiting.\n",
        "\n",
        "2) Lightweight Tasks:\n",
        "\n",
        "If the tasks are not CPU-intensive, using threads can be more efficient as the overhead of creating and managing threads is lower compared to processes.\n",
        "\n",
        "3) Shared Memory Requirements:\n",
        "\n",
        "When tasks need to share large amounts of data frequently, multithreading is preferable since threads share the same memory space, reducing the complexity of data sharing.\n",
        "\n",
        "4) Responsiveness:\n",
        "\n",
        "In applications like GUI applications where maintaining responsiveness is crucial , multithreading can help keep the user interface responsive while background tasks are processed.\n",
        "\n",
        "5) Real-Time Applications:\n",
        "\n",
        "When quick task switching is needed, such as in real-time applications, threads can provide better performance due to lower context-switching overhead.\n",
        "\n",
        "Multiprocessing:\n",
        "\n",
        "Definition: Multiprocessing involves running multiple processes, each with its own memory space. Processes do not share memory, making them more isolated from each other.\n",
        "\n",
        "Preferable scenarios:\n",
        "\n",
        "1) CPU-Bound Tasks:\n",
        "\n",
        "For tasks that require significant CPU processing power (e.g., mathematical computations, data processing), multiprocessing can leverage multiple CPU cares effectively, allowing parallel execution.\n",
        "\n",
        "2) Stability and Isolation:\n",
        "\n",
        "Since processes are isolated, if one crashes, it does not affect others. This is beneficial in applications where stability is critical.\n",
        "\n",
        "3) Memory Limitations:\n",
        "\n",
        "If the application requires significant memory usage, multiprocessing can be beneficial  because each process has its own memory space, preventing memory bloat in a single process.\n",
        "\n",
        "4) CPU-bound workloads in shared-memory systems:\n",
        "\n",
        "On systems with multiple CPUs/cores, multiprocessing can utilize the hardware effectively, distributing workload across processors.\n",
        "\n",
        "5) Complex applications:\n",
        "\n",
        "In applications that require complex computations or operations taht can be easily divided into separate tasks (like web servers handling multiple requests), multiprocessing can provide better performance.\n",
        "\n",
        "* Choose Mutipliprocessing when:\n",
        "\n",
        "* Tasks are CPU-bound and require significant processing power.\n",
        "\n",
        "* You need stability and isolation between tasks.\n",
        "\n",
        "* The workload is heavy and can be effectively parallelized across multiple cores.\n",
        "\n",
        "\n",
        "\n",
        "#2)\n",
        "\n",
        "Solution:\n",
        "\n",
        "A process pool is a programming abstraction that simplifies the management of multiple processes. It refers to a collection or \"pool\" of worker processes that can execute tasks concurrently. Instead of manually creating and managing processes for parallel execution, aprocess pool handles task distribution and manages the lifecycle of these processes, allowing for efficient execution and parallelism.\n",
        "\n",
        "Key concept of a Process pool:\n",
        "\n",
        "1) Pre-Created Processes:\n",
        "\n",
        "A process pool is created of a fixed number of worker processes that are created beforehead. These workers sits idle, waiting for tasks to be assigned to them.\n",
        "\n",
        "2) Task Assignment:\n",
        "\n",
        "When tasks are submitted to the pool, they are distributed among the available worker processes. The pool automatically handles which worker process will executeeach task. If all workers are busy, tasks are queued untill a worker becomes available.\n",
        "\n",
        "3) Reusing Processes:\n",
        "\n",
        "Once a worker process finishes executing its assigned task, it doesn't terminate. Instead, it becomes available to the next task. The reuse of processes avoids the overhead of constantly creating and destroying processes.\n",
        "\n",
        "4) Parallel Execution:\n",
        "\n",
        "Since processes in a pool can run concurrently, tasks that can be executed in benefit from the muti-core capabilities of modern CPUs. Each worker process can run on a separate CPU core, maximizing performance for CPU-bound tasks.\n",
        "\n",
        "5) Efficient Resource Management:\n",
        "\n",
        "The pool ensures that the number of processes running at any time is limited to a predefined maximum, preventing system resurces from being overwelhmed by too many processes. This is especially important in environments with limited resources.\n",
        "\n",
        "6) Task Queue:\n",
        "\n",
        "If more tasks are submitted than there are available workers, the excess tasks are placed in a queue. As workers become available , they pick up tasks from the queue, ensuring that no task is last or ignored.\n",
        "\n",
        "Example of Using Process Pool (Python's multiprocessing.Pool):\n",
        "\n"
      ],
      "metadata": {
        "id": "Gx_InmKZR_yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "def square(x):\n",
        "  return x * x\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  #create a pool with 4 worker processes\n",
        "  with multiprocessing.Pool(processes=4) as pool:\n",
        "    # Map the 'square' function to a list of inputs\n",
        "    results = pool.map(square, [1,2,3,4,5])\n",
        "    print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpfoQrb-JUiz",
        "outputId": "61ad8b59-317c-4d90-a0b4-5ba880a51f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Benefits of a Process Pool:\n",
        "\n",
        "1) Simplifies Process Management:\n",
        "\n",
        "Managing multiple processes can be complex, especially in larger applications. Process pools abstract away much of this complexity by handling task distribution, process reuse, and synchronisation.\n",
        "\n",
        "2) Efficient Resource Utilization:\n",
        "\n",
        "By reusing a fixed number of processes, a process pool reduces the overhead associated with repeatedly creating and destroying processes. It also prevents oversubscription of system resources, like CPU and memory, by limiting the number of concurrent processes.\n",
        "\n",
        "3) Concurrency Without Overhead:\n",
        "\n",
        "Process pools help achieve concurrency without overwelhming the system. You can set up the pool size that matches the number of CPU cores or based on available system resources, ensuring that your application doesn't spawn too many processes, leading to performance bottlenecks.\n",
        "\n",
        "4) Parallelism:\n",
        "\n",
        "For CPU-bound tasks, using a process pool allows for true parallelism, leveragingmultiple CPU cores to execute tasks simultanously, thus improving performance for computationally intensive applications.\n",
        "\n",
        "#3)\n",
        "\n",
        "Solution:\n",
        "\n",
        "Multiprocessing is a programming technique that allows multiple processes to run concurrently, enabling the execution of multiple tasks at the same time by utilizing multiple CPU cores. Each process runs independently in its own memory space, which allows for true parallelism, especially for CPU-bound tasks.\n",
        "\n",
        "Use of Mutiprocessing in Python Programs:\n",
        "\n",
        "In Python, the multiprocessing module is used to create and manage multiple processes. It is an essential tool when working with tasks that need to be executed in parallel, particularly when tasks require heavy computation and need to make full use of available system resources like CPU cores.\n",
        "\n",
        "1) Bypass Python's Global Interpreter Lock(GIL):\n",
        "\n",
        "* Python Global Interpreter LOck(GIL) is a mechanism that allows only one thread to execute python bytecode at a time, even on multi-core systems. This can be a bottleneck when using multithreading for CPU-bound tasks.\n",
        "\n",
        "* Multiprocessing bypass the GIL by running separate processes, each with its own Python interpreter and memory space, alllowing multiple processes to run simultaneously on multiple cores. This provides true parallelism and improves performance for CPU-intensive tasks.\n",
        "\n",
        "2) Parallel Execution on Multi-core CPUs:\n",
        "\n",
        "Modern processors came with multiple cores and multiplprocessing allows programs to fully utilize these cores. While threads in Python are limited by GIL, multiple processes can run independently on different cores, leading to significant performance improvements for computationally inteansive tasks.\n",
        "\n",
        "3) Improved Performance for CPU-bound Tasks:\n",
        "\n",
        "* Tasks that require heavy computation (like numerical calculations, data processing, image processing etc.) can be split across multiple processes. Each process can executebon a different CPU core, thus speeding up the overall execution time by running these tasks in parallel\n",
        "\n",
        "* Tasks that benefits from multiprocessing include machine learning model training, scientific computing, large-scale simulations, etc.\n",
        "\n",
        "4) Process Isolation for Stability:\n",
        "\n",
        "Each process in multiprocessing runs in its own memory space, which provides isolation. If one process crashes, it does not affect the others, and the memory used by the one process is not accessible by the others. This makes multiprocessing a more stable option compared to multithreading, where memory corruption in one thread could impact others.\n",
        "\n",
        "5) Concurrency in Task Execution:\n",
        "\n",
        "Multiprocessing is useful for achoeving concurrency (the ability to manage multiple tasks at a time). It can handle both CPU-bound tasks (where parallelism is important) and I/O-bound tasks (where tasks need to wait for input/output operations such as file reading or network requests).\n",
        "\n",
        "6) Parallelism with shared Memory Pipes:\n",
        "\n",
        "In Python, the multiprocessing module also supports sharing data between processes. You can share memory using shared memory objects or pipes for inter-process communication. While this is more complicated than in multithreading (where threads share memory by default), it ensures safe communication between processes when needed.\n",
        "\n",
        "Example of Using Multiprocessing in Python:\n"
      ],
      "metadata": {
        "id": "u4amfghZOjVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "# Function to be run in parallel\n",
        "def calculate_square(number):\n",
        "  return number * number\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  numbers = [1,2,3,4,5]\n",
        "\n",
        "  # create a pool at processes\n",
        "  pool = multiprocessing.Pool(processes=4)\n",
        "\n",
        "  #Use the pool to run the function in parallel\n",
        "  result = pool.map(calculate_square, numbers)\n",
        "  print(result)"
      ],
      "metadata": {
        "id": "qIaAxlK6bDDM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ef7e21a-f840-4dc5-d4c0-c1859edbf68d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Common Use Cases for Multiprocessing in Python:\n",
        "\n",
        "* Scientific Computing:\n",
        "\n",
        "Many scientific and engineering applications require complex calculations that can be distributed across multiple CPU cores using multiprocessing. Examples include simulations, data analysis, and machine learning model training.\n",
        "\n",
        "* Web Scraping:\n",
        "\n",
        "When scraping data from the web, multiprocessing can be used to scrape multiple pages in parallel, speeding up the overall process.\n",
        "\n",
        "* Data Processing:\n",
        "\n",
        "Large datasets that need to be processed (like in big data or machine learning applications) can be divided into smaller chunks, and each chunk can be processed in parallel using multiprocessing, reducing the total processing time.\n",
        "\n",
        "* Rendering and Image Processing:\n",
        "\n",
        "Applications that deal with rendering (e.g., 3D graphics, image manipulation) often benefits from multiprocessing since rendering tasks are computationally intensive and can be parallelized.\n",
        "\n",
        "**  Multiprocessing in Python is used for achieving parallelism by running multiple independent processes on multiple CPU cores. It is especially useful for CPU-bound tasks that need to bypass Python GIL and fully utilize available hardware resources. By using multiprocessing, Python programs can handle larger workloads efficiently, improing performance for computationally intensive tasks, ensuring better stability through process isolation, and making full use of modern multi-core processors.\n",
        "\n"
      ],
      "metadata": {
        "id": "U1hOKnjUI4VD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4)\n",
        "\n",
        "Solution:"
      ],
      "metadata": {
        "id": "ulOG5M6PM6IL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "# Shared resource: a list of numbers\n",
        "numbers = []\n",
        "\n",
        "# Create a lock object\n",
        "lock = threading.Lock()\n",
        "\n",
        "# Function to add numbers to the list\n",
        "def add_numbers():\n",
        "  for i in range(1,6): # Adds 5 numbers (1 to 5)\n",
        "    time.sleep(1) # simulating some delay\n",
        "    with lock:    # Acquiring the lock\n",
        "        numbers.append(i)\n",
        "        print(f\" Added {i}, List now: {numbers}\")\n",
        "\n",
        "\n",
        "# Function to remove numbers from the list\n",
        "def remove_numbers():\n",
        "  for _ in range(1,6): # Removes 5 numbers\n",
        "    time.sleep(2)  # Simulating some delay\n",
        "    with lock:     # Acquiring the lock\n",
        "      if numbers:\n",
        "        removed = numbers.pop(0)\n",
        "        print(f\" Removed {removed}, List now: {numbers}\")\n",
        "      else:\n",
        "        print(\" List is empty, nothing to remove. \")\n",
        "\n",
        "# Creating two threads: One for adding and one for removing numbers\n",
        "t1 = threading.Thread(target=add_numbers)\n",
        "t2 = threading.Thread(target=remove_numbers)\n",
        "\n",
        "# Start both threads\n",
        "t1.start()\n",
        "t2.start()\n",
        "\n",
        "# Wait for both threads to finish\n",
        "t1.join()\n",
        "t2.join()\n",
        "\n",
        "print(\"Final list:\", numbers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hwc22Df2Ngky",
        "outputId": "0f67ad19-7c6c-45d8-e332-2d5e899e5ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Added 1, List now: [1]\n",
            " Added 2, List now: [1, 2]\n",
            " Removed 1, List now: [2]\n",
            " Added 3, List now: [2, 3]\n",
            " Added 4, List now: [2, 3, 4]\n",
            " Removed 2, List now: [3, 4]\n",
            " Added 5, List now: [3, 4, 5]\n",
            " Removed 3, List now: [4, 5]\n",
            " Removed 4, List now: [5]\n",
            " Removed 5, List now: []\n",
            "Final list: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5)\n",
        "\n",
        "Solution:\n",
        "\n",
        "In Python, when working with multithreading or multiprocessing sharing data between threads or processes safely is crucial to avoid issues like race conditions and inconsistant states. Python provides various methods and tools for safely sharing data between threads (where memory is stored) and processes (where memory is not shared by default).\n",
        "\n",
        "1) Sharing data between Threads:\n",
        "\n",
        "Since threads share the same memory, data can be accessed directly by multiple threads. However, synchronisation machanisms are required to avoid race conditions and ensure safe data access.\n",
        "\n",
        "a) threading.Lock\n",
        "\n",
        "A lock ensures that only one thread can be access a shared resource at a time. When a thread acquires a lock, other threads attempting to acquire it will block untill it is released.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "_zkSW0gMSxFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "lock = threading.Lock()\n",
        "shared_data = 0\n",
        "import threading\n",
        "\n",
        "lock = threading.Lock()\n",
        "shared_data = 0\n",
        "\n",
        "def modify_data():\n",
        "  with lock:    # Acquiring the lock\n",
        "    global shared_data\n",
        "    shared_data += 1\n",
        "\n",
        "thread1 =  threading.Thread(target=modify_data)\n",
        "thread2 = threading.Thread(target=modify_data)\n",
        "\n",
        "thread1.start()\n",
        "thread2.start()\n",
        "\n",
        "thread1.join()\n",
        "thread2.join()\n",
        "\n",
        "print(shared_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X26rmBp_bdrH",
        "outputId": "81cc17cc-bc01-4918-a1bc-5b9e41650e94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) threading.RLock:\n",
        "\n",
        "An RLock (Reentrant Lock) is like a standard lock, but it allows a thread that has already acquired the lock to acquire it again without getting blocked. It is useful in recursive functions or when a thread needs to acquire the same lock multiple times.\n",
        "\n",
        "c) Condition (threading.Condition):\n",
        "\n",
        "A condition allows one or more threads to wait untill they are notified. It is typically used to manage complex synchronisation scenarios where a thread needs to wait for a certain condition before processing.\n",
        "\n",
        "Example:\n",
        "\n"
      ],
      "metadata": {
        "id": "XL2NsC9IdDr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "condition = threading.Condition()\n",
        "shared_data = 0\n",
        "\n",
        "def consumer():\n",
        "  with condition:\n",
        "    condition.wait()  # Wait for the producer to notify\n",
        "\n",
        "\n",
        "def producer():\n",
        "  global shared_data\n",
        "  with condition:\n",
        "    shared_data += 1\n",
        "    condition.notify()  # Notify the consumer\n",
        "\n",
        "threading.Thread(target=consumer).start()\n",
        "threading.Thread(target=producer).start()"
      ],
      "metadata": {
        "id": "ndx8nHzePXDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "d) Semaphore (threading.Semaphore):\n",
        "\n",
        "A semaphore is a synchronization primitive that allows a set number of threads to access a resource simultaneously. it is useful when you want to limit the nuber of threads accessing a shared resources.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "L93SUN_YQigU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "semaphore = threading.Semaphore(2)  # Allows up to 2 threads\n",
        "\n",
        "def access_shared_resource():\n",
        "  with semaphore:\n",
        "    print(\"Resource accessed\")\n",
        "\n",
        "\n",
        "thread1 = threading.Thread(target=access_shared_resource)\n",
        "thread2 = threading.Thread(target=access_shared_resource)"
      ],
      "metadata": {
        "id": "Zzim1Oc4RP-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "e) Event (threading>Event):\n",
        "\n",
        "An event allows thread to communicate with each other. It is used to flag one or more threads to start or stop execution.\n",
        "\n",
        "\n",
        "2) Sharing Data Between Processes:\n",
        "\n",
        "In multiprocessing, each process has its own memory space, which means data is not shared by default. Python's multiprocessing module provides tools to share data between processes safely.\n",
        "\n",
        "a) Shared Memory: (multiprocessing.Value, multiprocessing.Array):\n",
        "\n",
        "Value and Array allow you to share simple data types (like integers, floats) or arrays between processes.\n",
        "\n",
        "* Value: A shared, mutable object.\n",
        "\n",
        "* Array: A shared array of a specific data type.\n",
        "\n",
        "Example of Using ValueL"
      ],
      "metadata": {
        "id": "uSRhpBqESUwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Value\n",
        "\n",
        "\n",
        "def increment(shared_value):\n",
        "  with shared_value.get_lock():\n",
        "# Use an internal lock\n",
        "    shared_value.value += 1\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  shared_value = Value('i', 0)  # Create shared integer\n",
        "\n",
        "process1 = Process(target=increment, args=(shared_value,))\n",
        "process2 = Process(target=increment, args=(shared_value,))\n",
        "\n",
        "process1.start()\n",
        "process2.start()\n",
        "process1.join()\n",
        "process2.join()"
      ],
      "metadata": {
        "id": "siibRlCOUDqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Manager Objects (multiprocessing.Manager):\n",
        "\n",
        "Manager provides a way to share complex Python objects such as lists, dictionaries, and other mutable objects between processes. Manager objects are proxies that allow different processes to operate an shared data.\n",
        "\n",
        "Example of sharing a list using Manager:"
      ],
      "metadata": {
        "id": "qg63Hm0fV2z7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Manager\n",
        "\n",
        "def add_number(shared_list):\n",
        "  shared_list.append(1)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  manager = Manager()\n",
        "  shared_list = manager.list()\n",
        "\n",
        "process1 = Process(target=add_number, args=(shared_list,))\n",
        "process2 = Process(target=add_number, args=(shared_list,))\n",
        "\n",
        "process1.start()\n",
        "process2.start()\n",
        "process1.join()\n",
        "process2.join()\n",
        "\n",
        "print(shared_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ws8tYQEWiWw",
        "outputId": "d2e51ccc-eb9e-4298-fe95-ac78e72ac495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c) Queues (multiprocessing.Queue):\n",
        "\n",
        "Queue is a thread- and process-safe data structure used for sharing data between  threads or processes. I?t allows one or more producers to put data into the queue and one or more consumers to get data from it.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "QEGRFJc7X9TV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Queue\n",
        "\n",
        "def producer(queue):\n",
        "  queue.put(42)  # Pu data into the queue\n",
        "\n",
        "def consumer(queue):\n",
        "  print(queue.get())  # Get data from the queue\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  queue = Queue()\n",
        "  p1 = Process(target=producer, args=(queue,))\n",
        "  p2 = Process(target=consumer, args=(queue,))\n",
        "\n",
        "p1.start()\n",
        "p2.start()\n",
        "p1.join()\n",
        "p2.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_HWOVF3YkSj",
        "outputId": "942d330c-f4dc-46bf-f77c-4a36388a2882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d) Pipes (multiprocessing.Pipe):\n",
        "\n",
        "Pipe provides a way for two processes to communicate directly. It craetes two connection objects, one for each process, and allows the processes to send and recieve messages.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "ecGm4vvKaFyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process,Pipe\n",
        "\n",
        "def producer(conn):\n",
        "  conn.send(\"Hello from producer\")  # Send data to consumer\n",
        "  conn.close()\n",
        "\n",
        "def consumer(conn):\n",
        "  print(conn.recv())  # Recieve data\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  parent_conn, child_conn = Pipe()\n",
        "  p1 = Process(target=producer, args=(child_conn,))\n",
        "  p2 = Process(target=consumer, args=(parent_conn,))\n",
        "\n",
        "p1.start()\n",
        "p2.start()\n",
        "p1.join()\n",
        "p2.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMbbmOh8anEp",
        "outputId": "cba2431f-2d34-4a41-898b-2aac1f2cf2cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from producer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6)\n",
        "\n",
        "Solution:\n",
        "\n",
        "Handling exceptions in concurrent programs is crucial for ensuring that program run reliably, resources are managed correctly, and data integrity is maintained. In cncurrent programming, an exception in one thread or process can easily disrupt the entire application if not handled properly. Without proper handling, unhandled exceptions can lead to incomplete tasks, corrupted data, deadlocks, resource leaks, and difficulty in debugging.\n",
        "\n",
        "Exception Handling is crucial in Concurrent Programs:\n",
        "\n",
        "1) Ensure Program Stability:\n",
        "\n",
        "In concurrent environments, unhandeled exceptions in one threads or process can terminate it prematurely. If the exception is not managed, it could leave the application in an inconsistant state, especially if that thraed or process was responsible for a critical task.\n",
        "\n",
        "2) Prevents Deadlocks and Resource Leaks:\n",
        "\n",
        "Thraeds or processes that acquire locks or resources (like file handles, database connections, or network sockets) need to release them properly. If an exception occurs and is unhandled, these resources may remain locked or unreleased, causing deadlocks and resource leaks.\n",
        "\n",
        "3) Maintains Data Consistency:\n",
        "\n",
        "In concurrent applications, shared data is often accessed by multiple threads or processes. If an exception occurs mid-operation, it can leave shared data in a partially updated or inconsistant state, leading to data corruption.\n",
        "\n",
        "4) Improves Debugging and Maintenance:\n",
        "\n",
        "Handling exceptions provides more meaningful error messages and allows logging of failure points, which aids in debugging and identifying the root cause of issues in concurrent code.\n",
        "\n",
        "Techniques for Exception Handling in concurrent Programs:\n",
        "\n",
        "1) Using Try-Except Blocks Within Threads or Processes:\n",
        "\n",
        "Wrapping critical sections of concurrent code in try-except blocks is a fundamental way to catch exceptions. This allows threads or processes to handle errors locally and possibly recover without crashing the entire program.\n"
      ],
      "metadata": {
        "id": "Jswn1C4zcTOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "def worker():\n",
        "  try:   # Perform operations that may raise exceptions\n",
        "      pass\n",
        "  except Exception as e:\n",
        "    print(f\"Exception in worker thread: {e}\")\n",
        "\n",
        "thread = threading.Thread(target=worker)\n",
        "thread.start()\n",
        "thread.join()"
      ],
      "metadata": {
        "id": "QtsG8xlOh2Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Using Thread/Process Pool Error Handling:\n",
        "\n",
        "In Python, when using concurrent.futures.ThreadPoolExecutor or concurrent.futures.ProcessPoolExecutor, we can handle exceptions through Future objects. Futures provides a way to check if an exception was raised and retrieve the exception after the task has completed."
      ],
      "metadata": {
        "id": "5BvSar8Mi6sp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "def task():\n",
        "  # Potentially error-prone operation\n",
        "  raise ValueError(\"Something went wrong\")\n",
        "with ThreadPoolExecutor() as executor:\n",
        "  future = executor.submit(task)\n",
        "\n",
        "\n",
        "  try:\n",
        "    result = future.result()  # Retrieve result or raise exception\n",
        "  except Exception as e:\n",
        "    print(f\" Exception in thread pool: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFAPFjtmj0JG",
        "outputId": "d7a7afa0-2029-41ef-d121-357c23412b68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Exception in thread pool: Something went wrong\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Using Custom Exception classes\n",
        "\n",
        "Defining custom exception classes for specific errors allows for more precise handling . Threads or processes can raise these exceptions, which can be caught and handled appropriately in the main thread or process."
      ],
      "metadata": {
        "id": "KKlVvAjtl_qM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomException(Exception):\n",
        "  pass\n",
        "\n",
        "def worker():\n",
        "  try:\n",
        "    # Simulate an error\n",
        "    raise CustomException(\" Custom error occured\")\n",
        "  except CustomException as e:\n",
        "    print(f\" Caught custom exception: {e}\")"
      ],
      "metadata": {
        "id": "ovgdx3htm2Zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Using Callbacks for Exception Handling:\n",
        "\n",
        "Some concurrency libraries (like concurrent.futures) allow setting up callbacks that can handle results or exceptions when a task completes. Callbacks provides  a non-blocking way to process exception."
      ],
      "metadata": {
        "id": "AnJlLK5apCgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def task():\n",
        "  raise ValueError(\"Error in task\")\n",
        "\n",
        "def handle_result(future):\n",
        "  try:\n",
        "    future.result() # Check for exception\n",
        "  except Exception as e:\n",
        "    print(f\" Handled exception via callback: {e}\")\n",
        "\n",
        "with ThreadPoolExecutor() as executor:\n",
        "  future = executor.submit(task)\n",
        "\n",
        "future.add_done_callback(handle_result)\n",
        "with ThreadPoolExecutor() as executor:\n",
        "  future = executor.submit(task)\n",
        "\n",
        "future.add_done_callback(handle_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw588-tFp14O",
        "outputId": "bba22bbd-040e-4854-da63-c688eb45f3c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Handled exception via callback: Error in task\n",
            " Handled exception via callback: Error in task\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) Using Global Exception Handlers:\n",
        "\n",
        "In multi-threaded applications, setting a global exception hook can capture unhandled exceptions across threads, providing a final safety net."
      ],
      "metadata": {
        "id": "ewEHnWR3rjw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import sys\n",
        "\n",
        "def handle_thread_exception(exc_type, exc_value, exc_trackback):\n",
        "  print(f\" Unhandled exception: {exc_value}\")\n",
        "\n",
        "# Set global exception handler\n",
        "sys.excepthook = handle_thread_exception\n",
        "\n",
        "def worker():\n",
        "  raise RuntimeError(\" Unexpected error in thread\")\n",
        "\n",
        "thread = threading.Thread(target=worker)\n",
        "thread.start()\n",
        "thread.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUHCKHUXsFlZ",
        "outputId": "790b2d77-4345-45c9-8e46-04165ac36bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-18 (worker):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-31-9d3101f05947>\", line 11, in worker\n",
            "RuntimeError:  Unexpected error in thread\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) Graceful Shutdowns with finally or context Managers:\n",
        "\n",
        "Ensuring a graceful shutdown of resources (like releasing locks or closing files) is essential in concurrent programs. Using finally blocks or context managers ensures resources are released properly, even if an exception occurs."
      ],
      "metadata": {
        "id": "-O9JcmDNtkjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "lock = threading.Lock()\n",
        "\n",
        "def critical_section():\n",
        "  with lock:  # Lock is always released after with-block\n",
        "        # Perform operations\n",
        "        raise ValueError(\" Error during processing\")\n",
        "\n",
        "try:\n",
        "  critical_section()\n",
        "except Exception as e:\n",
        "    print(f\" Exception handled: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zawgw6ooueRS",
        "outputId": "75868e10-2e65-4913-b742-e4e934907fb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Exception handled:  Error during processing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7) Using Exception Queues for Multi-Process Exception Communication:\n",
        "\n",
        "In multiprocessing, each process has its own memory space, so exceptions raised in child processes. An exception queue can be used to send exceptions back to the parent process for handling."
      ],
      "metadata": {
        "id": "FnlBsSsivrsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Queue\n",
        "\n",
        "def worker(exception_queue):\n",
        "  try:\n",
        "    raise ValueError(\" Error in process\")\n",
        "  except Exception as e:\n",
        "    exception_queue.put(e)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "      exception_queue = Queue()\n",
        "      process = Process(target=worker, args=(exception_queue,))\n",
        "      process.start()\n",
        "      process.join()\n",
        "\n",
        "      if not exception_queue.empty():\n",
        "        exception = exception_queue.get()\n",
        "        print(f\" Handled exception from process: {exception}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj8NaSI7wa_n",
        "outputId": "9a2dc2c0-b161-4bb8-b050-0c44d10357e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Handled exception from process:  Error in process\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7)\n",
        "\n",
        "Solution:"
      ],
      "metadata": {
        "id": "dE0yXjiVzPZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from math import factorial\n",
        "\n",
        "# Function to calculate factorial of a number\n",
        "def calculate_factorial(n):\n",
        "  return n, factorial(n)\n",
        "\n",
        "# Function to use ThreadPoolExecutor\n",
        "def main():\n",
        "  numbers = range(1,11)  # Numbers from 1 to 10\n",
        "\n",
        "# Create a thread pool with ThreadPoolExecutor\n",
        "  with ThreadPoolExecutor() as executor:\n",
        "    # Submit tasks for each number\n",
        "    futures = {executor.submit(calculate_factorial, num): num for num in numbers}\n",
        "    for future in as_completed(futures):\n",
        "      num, fact = future.result()\n",
        "      print(f\"factorial of {num} is {fact}\")\n",
        "\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "        main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVpd04dtc1HK",
        "outputId": "52fc4684-1434-426f-ea59-7cb4d58863b3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "factorial of 2 is 2\n",
            "factorial of 4 is 24\n",
            "factorial of 9 is 362880\n",
            "factorial of 5 is 120\n",
            "factorial of 10 is 3628800\n",
            "factorial of 6 is 720\n",
            "factorial of 3 is 6\n",
            "factorial of 1 is 1\n",
            "factorial of 8 is 40320\n",
            "factorial of 7 is 5040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8)\n",
        "\n",
        "Solution:"
      ],
      "metadata": {
        "id": "eVx1AVQXhyIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "# Function to calculate the square of a number\n",
        "def square(n):\n",
        "  return n * n\n",
        "\n",
        "# Main function to execute the computation with different pool sizes\n",
        "def main():\n",
        "  numbers = range(1,11)  # Numbers from 1 to 10\n",
        "  pool_sizes = [2,4,8]  # Different pool sizes to test\n",
        "\n",
        "  for sizes in pool_sizes:\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Create a pool with the specified number of processes\n",
        "    with multiprocessing.Pool(processes=sizes) as pool:\n",
        "      # Map the square function to the number in the parallel\n",
        "      results = pool.map(square, numbers)\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f\"Pool size: {sizes}\")\n",
        "    print(\"Results:\", results)\n",
        "    print(f\"Time taken: {elapsed_time: .4f} seconds\\n\")\n",
        "\n",
        "# Run the main function:\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lF3qPh1Th2mb",
        "outputId": "35930960-f57b-42cc-f9bc-4d92a3fb43ec"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pool size: 2\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken:  0.0636 seconds\n",
            "\n",
            "Pool size: 4\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken:  0.0873 seconds\n",
            "\n",
            "Pool size: 8\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken:  0.1368 seconds\n",
            "\n"
          ]
        }
      ]
    }
  ]
}